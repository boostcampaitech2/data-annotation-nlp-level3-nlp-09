{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "#로그인 위치\n",
    "url = \"https://tagtog.net/-login\"\n",
    "\n",
    "#다운로드 위치\n",
    "file_url = 'https://tagtog/다운로드 링크' \n",
    "o_file = 'abc.zip'  \n",
    "if os.path.exists(o_file):\n",
    "    os.remove(o_file)\n",
    "\n",
    "#로그인 정보\n",
    "login_info = {\n",
    "    'loginid' : \"ID\",\n",
    "    'password' : \"PASSWORD\",\n",
    "}\n",
    "\n",
    "#로그인\n",
    "with requests.Session() as s:\n",
    "    login_req = s.post(url, data=login_info)\n",
    "    r = s.get(file_url)\n",
    "\n",
    "    with open(o_file,\"wb\") as output:\n",
    "        output.write(r.content)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#압축파일 풀기\n",
    "import zipfile\n",
    "import shutil\n",
    "folder_path = \"./tagtog_relation_extraction/\"\n",
    "\n",
    "zip_ = zipfile.ZipFile(\"abc.zip\")\n",
    "if os.path.exists(folder_path):\n",
    "    shutil.rmtree(folder_path)\n",
    "zip_.extractall(folder_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import json\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "#폴더 경로\n",
    "folder_name = \"./tagtog_relation_extraction/Q100/\"\n",
    "\n",
    "#context list\n",
    "context_name_list = os.listdir(folder_name + \"ann.json/master/pool\")\n",
    "\n",
    "#relation 폴더 경로\n",
    "relation_folder_paths = glob.glob(folder_name + \"ann.json/master/pool/*\")\n",
    "\n",
    "#context 폴더 경로\n",
    "# contexts_folders_paths = glob.glob(folder_name + \"plain.html/pool/*\")\n",
    "contexts_folders_paths = [folder_name + \"plain.html/pool/\" + c for c in context_name_list]\n",
    "\n",
    "\n",
    "#anntation_lenged 정보\n",
    "annotation_legend = folder_name + \"annotations-legend.json\"\n",
    "with open(annotation_legend,\"r\") as f:\n",
    "    annotation_legend = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "#relation dictionary 파일로부터 subject와 object의 entity 정보를 추출해주는 함수\n",
    "def get_needed_relation_data(tmp_relation):\n",
    "    subject_token = re.findall(\"\\(+(.+)+\\)\",annotation_legend[tmp_relation[\"relations\"][0]['classId']])[0].split(\"|\")[0]\n",
    "    if subject_token == tmp_relation['entities'][0]['classId']:\n",
    "        sub_entity, obj_entity = tmp_relation['entities']\n",
    "    else:\n",
    "        obj_entity, sub_entity  = tmp_relation['entities']\n",
    "    \n",
    "    # get preprocessed entities\n",
    "    def _get_entity(entity):\n",
    "        outputs = entity['offsets'][0]\n",
    "        outputs['type'] = annotation_legend[entity['classId']].split(\"-\")[1].lower()\n",
    "        return outputs\n",
    "    \n",
    "    output_subject = _get_entity(sub_entity)\n",
    "    output_object = _get_entity(obj_entity)\n",
    "    return output_subject, output_object"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#relation dictionary 파일로부터 title(relation)을 추출해주는 함수\n",
    "def get_label(relation_json):\n",
    "    label_tag = relation_json['relations'][0]['classId'] #r_6\n",
    "    try:\n",
    "        _,sub_type, label = annotation_legend[re.findall(\"\\(+(.+)+\\|\",annotation_legend[label_tag])[0]].split(\"-\")\n",
    "        return f\"{sub_type}:{label}\"\n",
    "    except:\n",
    "        _,sub_type, = annotation_legend[re.findall(\"\\(+(.+)+\\|\",annotation_legend[label_tag])[0]].split(\"-\")\n",
    "        return f\"{sub_type}:no_relation\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "#html 파일로부터 text만 추출해주는 함수\n",
    "def get_context_from_html(html_file):\n",
    "    html_file = re.sub(r\"\\n\",\"\", html_file)\n",
    "    return re.findall(\"(<pre.+>)(.+)(</pre>)\",html_file)[0][1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "#entity 정보가 포함된 sentence를 생성해주는 함수\n",
    "def get_sentence_with_entites(subject_entity, object_entity, sentence):\n",
    "    if subject_entity['start'] < object_entity['start']:\n",
    "        entity1,entity2 = subject_entity, object_entity\n",
    "    else:\n",
    "        entity1,entity2 = object_entity, subject_entity\n",
    "    \n",
    "    #entity 시작 위치 및 길이 \n",
    "    ett1_stt, ett1_len = entity1['start'], len(entity1['text'])\n",
    "    ett2_stt, ett2_len = entity2['start'], len(entity2['text'])\n",
    "    \n",
    "    #문장 분리\n",
    "    bf, ett1, mid, ett2, af = sentence[:ett1_stt], \\\n",
    "                            sentence[ett1_stt:ett1_stt+ett1_len], \\\n",
    "                            sentence[ett1_stt+ett1_len:ett2_stt], \\\n",
    "                            sentence[ett2_stt:ett2_stt+ett2_len], \\\n",
    "                            sentence[ett2_stt+ett2_len:]\n",
    "\n",
    "    \n",
    "    if subject_entity['start'] < object_entity['start']:\n",
    "        ett1,ett2 = f\"<sbj:{ett1}>\", f\"<obj:{ett2}>\"\n",
    "    else:\n",
    "        ett1,ett2 = f\"<obj:{ett1}>\", f\"<sbj:{ett2}>\"\n",
    "    \n",
    "    return \"\".join([bf, ett1, mid, ett2, af])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#dataframe column\n",
    "# id : context title(e.g : 카카오게임, 11번가 등)\n",
    "# sentence w/o entity\n",
    "# sentence w entity\n",
    "# subject_entity\n",
    "# object_entity\n",
    "# class\n",
    "\n",
    "id_list = []\n",
    "sentence_list = []\n",
    "sentence_with_entities_list = []\n",
    "subject_entity_list = []\n",
    "object_entity_list = []\n",
    "relation_list = []\n",
    "\n",
    "\n",
    "# tagtog 데이터를 CSV 형태로 변경\n",
    "for context_name, relation_folder, contexts_folder in zip(context_name_list, relation_folder_paths, contexts_folders_paths):\n",
    "    # relation files와 context files 리스트 출력\n",
    "    file_ids = [file_name.split(\".txt.\")[0] for file_name in os.listdir(relation_folder)]\n",
    "    file_nums = [ids.split(\"-\")[1] for ids in file_ids]\n",
    "    relation_files = [relation_folder + \"/\"+ file_id + \".txt.ann.json\" for file_id in file_ids]\n",
    "    context_files = [contexts_folder + \"/\"+ file_id + \".txt.plain.html\" for file_id in file_ids]\n",
    "    \n",
    "    #json으로 된 relation data와 html로 된 context 데이터 읽기\n",
    "    for relation_file, context_file, file_num in zip(relation_files,context_files, file_nums):\n",
    "        \n",
    "        #subject, object 정보 추출\n",
    "        with open(relation_file, \"r\") as f:\n",
    "            relation_json = json.load(f)\n",
    "        try:\n",
    "            tmp_subject, tmp_object = get_needed_relation_data(relation_json) #subject, object\n",
    "            tmp_label = get_label(relation_json)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        #sentence, sentence with entities 정보 추출\n",
    "        with open(context_file, \"r\") as f:\n",
    "            context_json = f.read()\n",
    "        tmp_sentence = get_context_from_html(context_json)\n",
    "        tmp_sentence_w_entities = get_sentence_with_entites(tmp_subject,tmp_object,tmp_sentence)\n",
    "        \n",
    "        #각 list에 데이터 저장\n",
    "        id_list.append(f\"{context_name}_{file_num}\")\n",
    "        sentence_list.append(tmp_sentence)\n",
    "        sentence_with_entities_list.append(tmp_sentence_w_entities)\n",
    "        subject_entity_list.append(tmp_subject)\n",
    "        object_entity_list.append(tmp_object)\n",
    "        relation_list.append(tmp_label.lower())\n",
    "#dataframe column\n",
    "# \"id\",\"sentence\",\"sentence_with_entity\",\"subject_entity\",\"object_entity\",\"class\"\n",
    "out_sentence = pd.DataFrame({'id': id_list, 'sentence' : sentence_list, 'sentence_with_entity': sentence_with_entities_list, \n",
    "                                       'subject_entity': subject_entity_list,'object_entity': object_entity_list,\n",
    "                                       'class': relation_list})\n",
    "out_sentence.to_csv('ano.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# 참고 자료 : \n",
    "\n",
    "# !pip install gspread\n",
    "# !pip install oauth2client\n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "#json key file 위치\n",
    "json_file_name = './gspread-331911-f882df8040e4.json'\n",
    "\n",
    "# json key file을 이용하여 접속\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(json_file_name, scope)\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "#구글 스프레드 시트 주소\n",
    "spreadsheet_url = \"주소\"\n",
    "\n",
    "# 스프레드시트 문서 가져오기\n",
    "doc = gc.open_by_url(spreadsheet_url)\n",
    "## gc.create(spreadsheet_name) # 스프레드시트 생성\n",
    "\n",
    "\n",
    "#시트 선택하기\n",
    "sheet_name = \"q100\"\n",
    "worksheet = doc.worksheet(sheet_name) #해당 시트가 있는 경우 불러오기\n",
    "## 403 error가 뜰 경우, google sheets API를 활성시켜줘야 함"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# 시트의 모든 데이터 가져오기\n",
    "values = worksheet.get_all_values()\n",
    "header, rows = values[0], values[1:]\n",
    "data = pd.DataFrame(rows, columns=header)\n",
    "\n",
    "column_list = [\"id\",\"sentence\",\"sentence_with_entity\",\"subject_entity\",\"object_entity\",\"class\"]\n",
    "data = data[column_list]\n",
    "data.head()\n",
    "\n",
    "sen_list =  list(data.sentence_with_entity.values)\n",
    "len(sen_list)\n",
    "\n",
    "worksheet.resize(len(id_list)+1,10)\n",
    "list_range = f\"a2:f{len(id_list)+1}\"\n",
    "cell_list = worksheet.range(list_range)\n",
    "\n",
    "for i in range(len(cell_list)//len(column_list)):\n",
    "    cell_list[(6*i)].value = id_list[i]\n",
    "    cell_list[(6*i)+1].value = sentence_list[i]\n",
    "    cell_list[(6*i)+2].value = sentence_with_entities_list[i]\n",
    "    cell_list[(6*i)+3].value = str(subject_entity_list[i])\n",
    "    cell_list[(6*i)+4].value = str(object_entity_list[i])\n",
    "    cell_list[(6*i)+5].value = relation_list[i]\n",
    "worksheet.update_cells(cell_list)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1NTio3zDQ7HwVH26HkQkq0De3I5K6gaccVXrE-hufevI',\n",
       " 'updatedRange': 'ano!A2:F1040',\n",
       " 'updatedRows': 1039,\n",
       " 'updatedColumns': 6,\n",
       " 'updatedCells': 6234}"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}